commit 7b867bfd8a50ec44d44e8b687314fad02f1f4cd6
Author: Matt Pocock <team@aihero.dev>
Date:   Thu Nov 13 14:21:12 2025 +0000

    10.02.01 Implemented HITL on the backend

diff --git a/src/app/api/chat/agent.ts b/src/app/api/chat/agent.ts
index 46299fa..9ce8d17 100644
--- a/src/app/api/chat/agent.ts
+++ b/src/app/api/chat/agent.ts
@@ -1,9 +1,11 @@
 import {
   Experimental_Agent as Agent,
+  hasToolCall,
   LanguageModel,
   StopCondition,
   ToolSet,
   UIMessage,
+  UIMessageStreamWriter,
 } from "ai";
 import { MyMessage } from "./route";
 import { searchTool } from "./search-tool";
@@ -12,6 +14,7 @@ import { getEmailsTool } from "./get-emails-tool";
 import { DB } from "@/lib/persistence-layer";
 import { chatToText } from "@/app/utils";
 import { memoryToText } from "@/app/memory-search";
+import { makeHITLToolSet } from "./hitl";
 
 export const getTools = (messages: UIMessage[]) => ({
   search: searchTool(messages),
@@ -25,15 +28,23 @@ const USER_LAST_NAME = "Chen";
 export const createAgent = (opts: {
   messages: MyMessage[];
   model: LanguageModel;
   stopWhen: StopCondition<any>;
   memories: DB.Memory[];
   relatedChats: DB.Chat[];
   mcpTools: ToolSet;
+  writer?: UIMessageStreamWriter;
 }) =>
   new Agent({
     model: opts.model,
-    tools: { ...getTools(opts.messages), ...opts.mcpTools },
-    stopWhen: opts.stopWhen,
+    tools: {
+      ...getTools(opts.messages),
+      ...makeHITLToolSet(opts.mcpTools, opts.writer),
+    },
+    stopWhen: [
+      opts.stopWhen,
+      // Stop when any MCP tool is called
+      ...Object.keys(opts.mcpTools).map((toolName) => hasToolCall(toolName)),
+    ],
     system: `
 <task-context>
 You are a personal assistant to ${USER_FIRST_NAME} ${USER_LAST_NAME}. You help with general tasks, questions, and can access ${USER_FIRST_NAME}'s email when needed.
diff --git a/src/app/api/chat/hitl.ts b/src/app/api/chat/hitl.ts
new file mode 100644
index 0000000..355c518
--- /dev/null
+++ b/src/app/api/chat/hitl.ts
@@ -0,0 +1,200 @@
+import {
+  convertToModelMessages,
+  ModelMessage,
+  ToolSet,
+  UIMessageStreamWriter,
+} from "ai";
+import { MyMessage } from "./route";
+
+export type ToolApprovalDecision =
+  | {
+      type: "approve";
+    }
+  | {
+      type: "reject";
+      reason: string;
+    };
+
+export type ToolApprovalDataParts = {
+  "approval-request": {
+    tool: ToolRequiringApproval;
+  };
+  "approval-decision": {
+    // The original tool ID that this decision is for.
+    toolId: string;
+    decision: ToolApprovalDecision;
+  };
+  "approval-result": {
+    output: unknown;
+    // The original tool ID that this output is for.
+    toolId: string;
+  };
+};
+
+export type ToolRequiringApproval = {
+  // The id of the request
+  id: string;
+  // The name of the tool as it appears in the MCP
+  name: string;
+  // The input to the tool
+  input: unknown;
+};
+
+export const annotateMessageHistory = (
+  messages: MyMessage[]
+): ModelMessage[] => {
+  const modelMessages = convertToModelMessages<MyMessage>(messages, {
+    convertDataPart(part) {
+      if (part.type === "data-approval-request") {
+        return {
+          type: "text",
+          text: `The assistant requested to run the tool: ${
+            part.data.tool.name
+          } with input: ${JSON.stringify(part.data.tool.input)}`,
+        };
+      }
+      if (part.type === "data-approval-decision") {
+        if (part.data.decision.type === "approve") {
+          return {
+            type: "text",
+            text: "The user approved the tool.",
+          };
+        }
+        return {
+          type: "text",
+          text: `The user rejected the tool: ${part.data.decision.reason}`,
+        };
+      }
+
+      if (part.type === "data-approval-result") {
+        return {
+          type: "text",
+          text: `The tool returned this result: ${JSON.stringify(
+            part.data.output
+          )}`,
+        };
+      }
+    },
+  });
+
+  return modelMessages;
+};
+
+export type HITLError = {
+  message: string;
+  status: number;
+};
+
+export type HITLDecisionsToProcess = {
+  tool: ToolRequiringApproval;
+  decision: ToolApprovalDecision;
+};
+
+export const findDecisionsToProcess = (opts: {
+  mostRecentUserMessage: MyMessage;
+  mostRecentAssistantMessage: MyMessage | undefined;
+}): HITLError | HITLDecisionsToProcess[] => {
+  const { mostRecentUserMessage, mostRecentAssistantMessage } = opts;
+
+  // If there's no assistant message in the chat, there's nothing to process.
+  if (!mostRecentAssistantMessage) {
+    return [];
+  }
+
+  // Get all the tools that the assistant has started
+  const tools = mostRecentAssistantMessage.parts
+    .filter((part) => part.type === "data-approval-request")
+    .map((part) => part.data.tool);
+
+  // Get all the decisions that the user has made
+  const decisions = new Map(
+    mostRecentUserMessage.parts
+      .filter((part) => part.type === "data-approval-decision")
+      .map((part) => [part.data.toolId, part.data.decision])
+  );
+
+  const decisionsToProcess: HITLDecisionsToProcess[] = [];
+
+  for (const tool of tools) {
+    const decision = decisions.get(tool.id);
+
+    // If no decision is found, return an error - the user
+    // should make a decision before continuing.
+    if (!decision) {
+      return {
+        message: `No decision found for tool ${tool.id}`,
+        status: 400,
+      };
+    }
+
+    decisionsToProcess.push({
+      tool,
+      decision,
+    });
+  }
+
+  return decisionsToProcess;
+};
+
+export const executeHITLDecisions = async (opts: {
+  decisions: HITLDecisionsToProcess[];
+  mcpTools: ToolSet;
+  writer: UIMessageStreamWriter<MyMessage>;
+  messages: MyMessage[];
+}) => {
+  for (const { tool, decision } of opts.decisions) {
+    if (decision.type === "approve") {
+      const result = await opts.mcpTools[tool.name].execute?.(tool.input, {
+        messages: [],
+        toolCallId: "foo",
+      });
+
+      const messagePart = {
+        type: "data-approval-result" as const,
+        data: {
+          toolId: tool.id,
+          output: result,
+        },
+      };
+
+      // Send the result to the client
+      opts.writer.write(messagePart);
+
+      // Add the message part to the last message in the messages array
+      opts.messages[opts.messages.length - 1].parts.push(messagePart);
+    }
+  }
+
+  return opts.messages;
+};
+
+export const makeHITLToolSet = (
+  tools: ToolSet,
+  writer: UIMessageStreamWriter<MyMessage> | undefined
+) => {
+  const toolEntries = Object.entries(tools);
+
+  const newTools: ToolSet = {};
+
+  for (const [toolName, tool] of toolEntries) {
+    newTools[toolName] = {
+      ...tool,
+      execute: async (input) => {
+        writer?.write({
+          type: "data-approval-request",
+          data: {
+            tool: {
+              id: crypto.randomUUID(),
+              input,
+              name: toolName,
+            },
+          },
+        });
+
+        return "Requested tool execution";
+      },
+    };
+  }
+
+  return newTools;
+};
diff --git a/src/app/api/chat/route.ts b/src/app/api/chat/route.ts
index f9009cc..3a5f8eb 100644
--- a/src/app/api/chat/route.ts
+++ b/src/app/api/chat/route.ts
@@ -10,17 +10,22 @@ import {
 } from "@/lib/persistence-layer";
 import { google } from "@ai-sdk/google";
 import {
-  convertToModelMessages,
   createUIMessageStream,
   createUIMessageStreamResponse,
   InferUITools,
   safeValidateUIMessages,
   stepCountIs,
   UIMessage,
 } from "ai";
 import { createAgent, getTools } from "./agent";
 import { extractAndUpdateMemories } from "./extract-memories";
 import { generateTitleForChat } from "./generate-title";
+import {
+  annotateMessageHistory as annotateHITLMessageHistory,
+  executeHITLDecisions,
+  findDecisionsToProcess,
+  ToolApprovalDataParts,
+} from "./hitl";
 import { getMCPTools } from "./mcp";
 
 // Allow streaming responses up to 30 seconds
@@ -33,139 +38,162 @@ const OLD_MESSAGES_TO_USE = 10;
 export type MyMessage = UIMessage<
   never,
   {
     "frontend-action": "refresh-sidebar";
-  },
+  } & ToolApprovalDataParts,
   InferUITools<ReturnType<typeof getTools>>
 >;
 
 export async function POST(req: Request) {
   const body: {
     message: MyMessage;
     id: string;
   } = await req.json();
 
   const chatId = body.id;
 
   let chat = await getChat(chatId);
 
   const recentMessages = [...(chat?.messages ?? []), body.message].slice(
     -MESSAGE_HISTORY_LENGTH
   );
 
   const olderMessages = chat?.messages.slice(0, -MESSAGE_HISTORY_LENGTH);
 
   const validatedMessagesResult = await safeValidateUIMessages<MyMessage>({
     messages: recentMessages,
   });
 
   if (!validatedMessagesResult.success) {
     return new Response(validatedMessagesResult.error.message, { status: 400 });
   }
 
   const messages = validatedMessagesResult.data;
 
   const mostRecentMessage = messages[messages.length - 1];
 
   if (!mostRecentMessage) {
     return new Response("No messages provided", { status: 400 });
   }
 
   if (mostRecentMessage.role !== "user") {
     return new Response("Last message must be from the user", {
       status: 400,
     });
   }
 
+  const mostRecentAssistantMessage = messages.findLast(
+    (message) => message.role === "assistant"
+  );
+
+  const hitlResult = findDecisionsToProcess({
+    mostRecentUserMessage: mostRecentMessage,
+    mostRecentAssistantMessage,
+  });
+
+  if ("status" in hitlResult) {
+    return new Response(hitlResult.message, {
+      status: hitlResult.status,
+    });
+  }
+
   const allMemories = await searchMemories({ messages });
 
   const memories = allMemories.slice(0, MEMORIES_TO_USE);
 
   const oldMessagesToUse = await searchMessages({
     recentMessages: messages,
     olderMessages: olderMessages ?? [],
   }).then((results) =>
     results
       .slice(0, OLD_MESSAGES_TO_USE)
       .sort((a, b) => b.score - a.score)
       .map((result) => result.item)
   );
 
   console.log("oldMessagesToUse", oldMessagesToUse.length);
 
   const messageHistoryForLLM = [...oldMessagesToUse, ...messages];
 
   const stream = createUIMessageStream<MyMessage>({
     execute: async ({ writer }) => {
       let generateTitlePromise: Promise<void> | undefined = undefined;
 
       if (!chat) {
         const newChat = await createChat({
           id: chatId,
           title: "Generating title...",
           initialMessages: messages,
         });
         chat = newChat;
 
         writer.write({
           type: "data-frontend-action",
           data: "refresh-sidebar",
           transient: true,
         });
 
         generateTitlePromise = generateTitleForChat(messages)
           .then((title) => {
             return updateChatTitle(chatId, title);
           })
           .then(() => {
             writer.write({
               type: "data-frontend-action",
               data: "refresh-sidebar",
               transient: true,
             });
           });
       } else {
         await appendToChatMessages(chatId, [mostRecentMessage]);
       }
 
       const relatedChats = await searchForRelatedChats(chatId, messages);
 
       const mcpTools = await getMCPTools();
 
+      const messagesWithToolResults = await executeHITLDecisions({
+        decisions: hitlResult,
+        mcpTools,
+        writer,
+        messages: messageHistoryForLLM,
+      });
+
       const agent = createAgent({
         memories: memories.map((memory) => memory.item),
         relatedChats: relatedChats.map((chat) => chat.item),
-        messages: messageHistoryForLLM,
+        messages: messagesWithToolResults,
         model: google("gemini-2.5-flash"),
         stopWhen: stepCountIs(10),
         mcpTools,
+        writer,
       });
 
       const result = agent.stream({
-        messages: convertToModelMessages(messageHistoryForLLM),
+        messages: annotateHITLMessageHistory(messagesWithToolResults),
       });
 
       writer.merge(
         result.toUIMessageStream({
           sendSources: true,
           sendReasoning: true,
         })
       );
 
       await generateTitlePromise;
     },
     generateId: () => crypto.randomUUID(),
     onFinish: async ({ responseMessage }) => {
       await appendToChatMessages(chatId, [responseMessage]);
       await extractAndUpdateMemories({
         messages: [...messages, responseMessage],
         memories: memories.map((memory) => memory.item),
       });
       await reflectOnChat(chatId);
     },
   });
 
   // send sources and reasoning back to the client
   return createUIMessageStreamResponse({
     stream,
   });
 }
